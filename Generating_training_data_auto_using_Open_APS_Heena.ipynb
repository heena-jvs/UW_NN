{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (1.16.11)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3) (1.19.11)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.25.4; python_version != \"3.4\" in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.20.0,>=1.19.11->boto3) (1.25.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.20.0,>=1.19.11->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.11->boto3) (1.14.0)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# %load Generating_training_data_auto_using_Open_APS.py\n",
    "# In[1]: Importing required libraries\n",
    "get_ipython().system('pip install boto3')\n",
    "get_ipython().system('pip install plotly')\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import plotly.graph_objects as go\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]:Paginating to see all data files and get participant IDs from S3 bucket\n",
    "\n",
    "REGION = 'us-west-2'\n",
    "ACCESS_KEY_ID = '************'\n",
    "SECRET_ACCESS_KEY = '*********************'\n",
    "BUCKET_NAME = 'uw-nn-data'\n",
    "s3c = boto3.client(\n",
    "        's3', \n",
    "        region_name = REGION,\n",
    "        aws_access_key_id = ACCESS_KEY_ID,\n",
    "        aws_secret_access_key = SECRET_ACCESS_KEY\n",
    "    )\n",
    "client = boto3.client('s3')\n",
    "paging_client = client.get_paginator('list_objects_v2')\n",
    "result = paging_client.paginate(Bucket='uw-nn-data', Prefix='OpenAPS/',  Delimiter='/', PaginationConfig={\n",
    "        'MaxItems': 1000,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00221634', '00309157', '00897741', '01352464', '01884126', '02033176', '03572116', '04762925', '05274556', '06593293', '06806689', '07886752', '12689381', '13029224', '13783771', '14092221', '15558575', '16975609', '17161370', '19626656', '20216809', '20396154', '20649783', '21946407', '22961398', '24448124', '24587372', '27700103', '28608066', '28756888', '32407882', '32635618', '32997134', '33470634', '34148224', '35533061', '35719805', '37764532', '37875431', '37998755', '38110191', '39986716', '40237051', '40634871', '40997757', '41263203', '41663654', '42052178', '43589707', '45025419', '45120081', '46253612', '47323535', '47750728', '52804089', '56568290', '60207627', '60844515', '61179686', '62345070', '62401782', '63047517', '64024750', '64406000', '66019205', '66773091', '66836068', '67208817', '67359234', '67539697', '68267781', '69587086', '69965708', '70454270', '70811987', '71236754', '71397255', '71618088', '73521474', '77104076', '77411181', '78420229', '79526193', '80373992', '80501215', '80625186', '80796147', '81099003', '81680176', '84081904', '84109428', '84589080', '84984656', '85653830', '86025410', '87770486', '88004055', '89710417', '89727223', '91161972', '92204064', '93606058', '93839818', '93937579', '94200862', '94875538', '95614431', '95851255', '96484928', '96805916', '97417885', '97872409', '98340749', '98974339', '99296581', '99712241', '99848889', '99908129']\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "# Making a list for all participant id data that is currently available in S3\n",
    "participant_ids = []\n",
    "for page in result:\n",
    "    if \"CommonPrefixes\" in page:\n",
    "        for prefix in page[\"CommonPrefixes\"]:\n",
    "            participant_ids.append(prefix['Prefix'][8:-1]) \n",
    "print(participant_ids)\n",
    "print(len(participant_ids)) #rechecking total number of participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02033176\n",
      "04762925\n",
      "14092221\n",
      "16975609\n",
      "84081904\n",
      "99712241\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# In[3]: Creating a dictionary with participant id as the key  \n",
    "         # and a list csv files (and number) for device status data as its value\n",
    "\n",
    "devicestatus_files_across_participants = {}\n",
    "num_devicestatus_files_across_participants = {}\n",
    "\n",
    "for participant_id in participant_ids:\n",
    "    num_devicestatus_files_for_this_participant = 0\n",
    "    devicestatus_files_for_this_participant = []\n",
    "\n",
    "    result = paging_client.paginate(Bucket='uw-nn-data', Prefix='OpenAPS/' + participant_id, PaginationConfig={\n",
    "        'MaxItems': 1000,\n",
    "    })\n",
    "\n",
    "    for page in result:\n",
    "        if \"Contents\" in page:\n",
    "            for key in page[\"Contents\"]:\n",
    "                if 'devicestatus' in key['Key']:\n",
    "                    num_devicestatus_files_for_this_participant += 1\n",
    "                    devicestatus_files_for_this_participant.append(key['Key'])\n",
    "    num_devicestatus_files_across_participants[participant_id] = num_devicestatus_files_for_this_participant\n",
    "# Filter for only those participants which have enough devicestatus data for analysing now\n",
    "    if num_devicestatus_files_for_this_participant ==8 : #based on how much devicestatus data we need, please change here\n",
    "        devicestatus_files_across_participants[participant_id] = devicestatus_files_for_this_participant\n",
    "        print(participant_id)\n",
    "print(len(devicestatus_files_across_participants))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#how many maximam device status files we have \n",
    "max_num_devicestatus_files_across_participants = 0\n",
    "for participant_id in num_devicestatus_files_across_participants:\n",
    "    if num_devicestatus_files_across_participants[participant_id] > max_num_devicestatus_files_across_participants:\n",
    "        max_num_devicestatus_files_across_participants = num_devicestatus_files_across_participants[participant_id]\n",
    "print(max_num_devicestatus_files_across_participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32635618\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#how many minimum device status files we have \n",
    "min_num_devicestatus_files_across_participants = 1\n",
    "for participant_id in num_devicestatus_files_across_participants:\n",
    "    if num_devicestatus_files_across_participants[participant_id] < min_num_devicestatus_files_across_participants:\n",
    "        min_num_devicestatus_files_across_participants = num_devicestatus_files_across_participants[participant_id]\n",
    "        if num_devicestatus_files_across_participants[participant_id] == 0:\n",
    "            print(participant_id)\n",
    "print(min_num_devicestatus_files_across_participants)\n",
    "#just analysing what are maximam and min number of device status files from our S3 bucket data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]:Creating a dict with participant IDs key \n",
    "       #and list of with only those device status files where eventualBG, bg, rate columns and timestamps appear as its value\n",
    "    \n",
    "devicestatus_files_to_be_merged_for_this_participant_across_participants = {}\n",
    "\n",
    "for participant in devicestatus_files_across_participants:\n",
    "    devicestatus_files_to_be_merged_for_this_participant = []\n",
    "    \n",
    "    # Iterate through all device status files for this participant and append\n",
    "    # eligible files with bg, eventual bg and rate to devicestatus_files_to_be_merged_for_this_participant\n",
    "    for file in devicestatus_files_across_participants[participant]:\n",
    "        obj = s3c.get_object(Bucket= 'uw-nn-data', Key = file)\n",
    "        lines = obj['Body'].read().decode('utf-8').splitlines(True)\n",
    "        column_names = lines[0].split(\",\")\n",
    "        if ('openaps/enacted/bg' in column_names) and ('openaps/enacted/eventualBG' in column_names) and ('openaps/enacted/rate' in column_names) and ('openaps/enacted/timestamp' in column_names):\n",
    "            devicestatus_files_to_be_merged_for_this_participant.append(file) #when we need mor columns, just add their names here\n",
    "\n",
    "    # Now assign all appended eligible files list as value to respective participant id as key \n",
    "    # in dict devicestatus_files_to_be_merged_for_this_participant_across_participants, \n",
    "    #if there are no such device status files, we don't those participants at this point\n",
    "    if len(devicestatus_files_to_be_merged_for_this_participant) >0 :\n",
    "        devicestatus_files_to_be_merged_for_this_participant_across_participants[participant] = devicestatus_files_to_be_merged_for_this_participant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (228,229,230,232,233,240,243,246,249,250,254,257,266,441,444) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (463) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (13,20,23,41,331,450) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (308) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (364) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (366) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (426) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (293) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,16,18,19,22,23,24,25,26,35,127,130,478) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (4,5,449) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (205) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (289) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (278) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (75) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (127) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,24,28,29,170) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (3,5,6,7,8,9,12,13,20,22,97,102,103,105,110,111,114,120,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# In[5]:Creating dict with participant ID as key and list of training data files as its key \n",
    "        #by reading csv device statusdata files in S3 to create training data files each with 4 headers in original data \n",
    "        #'openaps/enacted/timestamp','openaps/enacted/bg','openaps/enacted/eventualBG','openaps/enacted/rate' and remove NAN values\n",
    "devicestatus_training_files_to_be_merged_for_each_participant = {}\n",
    "for participant in devicestatus_files_to_be_merged_for_this_participant_across_participants:\n",
    "    devicestatus_training_files_to_be_merged_for_this_participant=[]\n",
    "    for file in devicestatus_files_to_be_merged_for_this_participant_across_participants[participant]:\n",
    "        obj = s3c.get_object(Bucket= 'uw-nn-data', Key = file)\n",
    "        reading_device_status_eligible_file = pd.read_csv(io.BytesIO(obj['Body'].read()), encoding='utf8')\n",
    "        reading_device_status_eligible_file_train = reading_device_status_eligible_file.loc[:,['openaps/enacted/timestamp','openaps/enacted/bg','openaps/enacted/eventualBG','openaps/enacted/rate']].drop_duplicates()\n",
    "        reading_device_status_eligible_file_train.dropna(inplace=True)\n",
    "        devicestatus_training_files_to_be_merged_for_this_participant.append(reading_device_status_eligible_file_train)\n",
    "    devicestatus_training_files_to_be_merged_for_each_participant[participant] = devicestatus_training_files_to_be_merged_for_this_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]:concatenating all eligible files listed as value in devicestatus_training_files_to_be_merged_for_each_participant[participant]  \n",
    "devicestatus_training_files_combined_for_each_participant = {}\n",
    "for participant in devicestatus_training_files_to_be_merged_for_each_participant:\n",
    "   #defining empty dataframe to concatenate all device status files in to one trainin dataset for each participant\n",
    "    devicestatus_training_files_combined_for_this_participant = pd.DataFrame()   \n",
    "    for file in devicestatus_training_files_to_be_merged_for_each_participant[participant]:\n",
    "        if devicestatus_training_files_combined_for_this_participant.empty:\n",
    "            devicestatus_training_files_combined_for_this_participant = file\n",
    "        else:\n",
    "            devicestatus_training_files_combined_for_this_participant = pd.concat([devicestatus_training_files_combined_for_this_participant, file], ignore_index=True)\n",
    "    devicestatus_training_files_combined_for_each_participant[participant]=devicestatus_training_files_combined_for_this_participant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print (len(devicestatus_training_files_combined_for_each_participant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           openaps/enacted/timestamp  openaps/enacted/bg  \\\n",
      "215 2019-06-19 12:32:51.992000+00:00               195.0   \n",
      "225        2019-06-19 13:45:01+00:00               144.0   \n",
      "224        2019-06-19 13:50:00+00:00               139.0   \n",
      "223        2019-06-19 13:51:03+00:00               139.0   \n",
      "222        2019-06-19 14:07:10+00:00               121.0   \n",
      "..                               ...                 ...   \n",
      "4          2019-06-22 12:11:36+00:00               121.0   \n",
      "3          2019-06-22 12:25:53+00:00               122.0   \n",
      "2          2019-06-22 14:09:49+00:00               177.0   \n",
      "1   2019-06-22 14:43:29.942000+00:00               188.0   \n",
      "0   2019-06-22 14:54:13.601000+00:00               162.0   \n",
      "\n",
      "     openaps/enacted/eventualBG  openaps/enacted/rate  \n",
      "215                        39.0                   0.0  \n",
      "225                       183.0                   0.8  \n",
      "224                       176.0                   0.0  \n",
      "223                       177.0                   0.8  \n",
      "222                        87.0                   0.0  \n",
      "..                          ...                   ...  \n",
      "4                         322.0                   1.7  \n",
      "3                         280.0                   0.0  \n",
      "2                         401.0                   3.2  \n",
      "1                         176.0                   0.0  \n",
      "0                         125.0                   0.0  \n",
      "\n",
      "[226 rows x 4 columns]\n",
      "      openaps/enacted/timestamp  openaps/enacted/bg  \\\n",
      "13443 2017-10-13 16:39:22+00:00               151.0   \n",
      "13442 2017-10-13 16:52:20+00:00               183.0   \n",
      "13441 2017-10-13 16:57:49+00:00               185.0   \n",
      "13440 2017-10-13 17:18:20+00:00               193.0   \n",
      "13439 2017-10-13 17:28:26+00:00               199.0   \n",
      "...                         ...                 ...   \n",
      "4     2018-04-16 22:53:21+00:00               110.0   \n",
      "3     2018-04-16 23:06:45+00:00                97.0   \n",
      "2     2018-04-16 23:34:20+00:00                80.0   \n",
      "1     2018-04-16 23:46:43+00:00                77.0   \n",
      "0     2018-04-16 23:50:39+00:00                72.0   \n",
      "\n",
      "       openaps/enacted/eventualBG  openaps/enacted/rate  \n",
      "13443                       100.0                  1.45  \n",
      "13442                       182.0                  3.45  \n",
      "13441                       128.0                  1.45  \n",
      "13440                       150.0                  3.00  \n",
      "13439                       164.0                  3.80  \n",
      "...                           ...                   ...  \n",
      "4                            90.0                  0.00  \n",
      "3                            85.0                  0.00  \n",
      "2                            98.0                  0.00  \n",
      "1                           104.0                  1.20  \n",
      "0                            93.0                  0.00  \n",
      "\n",
      "[13444 rows x 4 columns]\n",
      "     openaps/enacted/timestamp  openaps/enacted/bg  \\\n",
      "8995 2016-11-06 06:03:10+00:00               152.0   \n",
      "8994 2016-11-06 06:32:26+00:00               180.0   \n",
      "8993 2016-11-14 00:50:00+00:00                90.0   \n",
      "8992 2016-11-14 05:49:35+00:00               161.0   \n",
      "8991 2016-11-14 06:51:11+00:00               135.0   \n",
      "...                        ...                 ...   \n",
      "4    2017-01-26 22:45:10+00:00               174.0   \n",
      "3    2017-01-26 23:14:15+00:00               193.0   \n",
      "2    2017-01-26 23:25:36+00:00               182.0   \n",
      "1    2017-01-26 23:36:56+00:00               171.0   \n",
      "0    2017-01-26 23:51:23+00:00               161.0   \n",
      "\n",
      "      openaps/enacted/eventualBG  openaps/enacted/rate  \n",
      "8995                       175.0                 1.000  \n",
      "8994                       205.0                 1.000  \n",
      "8993                        85.0                 0.000  \n",
      "8992                       110.0                 0.250  \n",
      "8991                       119.0                 0.050  \n",
      "...                          ...                   ...  \n",
      "4                          172.0                 2.000  \n",
      "3                          144.0                 0.675  \n",
      "2                          104.0                 0.575  \n",
      "1                          100.0                 0.575  \n",
      "0                           97.0                 0.575  \n",
      "\n",
      "[8996 rows x 4 columns]\n",
      "             openaps/enacted/timestamp  openaps/enacted/bg  \\\n",
      "15226 2019-09-25 21:22:17.390000+00:00               194.0   \n",
      "15225 2019-09-25 21:34:58.467000+00:00               180.0   \n",
      "15224 2019-09-26 07:54:38.864000+00:00               134.0   \n",
      "15223 2019-09-26 08:09:31.194000+00:00               130.0   \n",
      "15222 2019-09-26 08:11:54.688000+00:00               130.0   \n",
      "...                                ...                 ...   \n",
      "4     2020-06-02 13:28:10.793000+00:00               216.0   \n",
      "3     2020-06-02 13:32:46.136000+00:00               214.0   \n",
      "2     2020-06-02 13:39:47.091000+00:00               214.0   \n",
      "1     2020-06-02 13:44:31.144000+00:00               214.0   \n",
      "0     2020-06-02 13:54:09.749000+00:00               212.0   \n",
      "\n",
      "       openaps/enacted/eventualBG  openaps/enacted/rate  \n",
      "15226                       137.0                   0.0  \n",
      "15225                       134.0                   0.0  \n",
      "15224                       113.0                   0.8  \n",
      "15223                       106.0                   0.8  \n",
      "15222                       111.0                   0.7  \n",
      "...                           ...                   ...  \n",
      "4                           124.0                   0.0  \n",
      "3                           128.0                   0.0  \n",
      "2                           145.0                   0.0  \n",
      "1                           140.0                   0.0  \n",
      "0                           146.0                   0.0  \n",
      "\n",
      "[15227 rows x 4 columns]\n",
      "     openaps/enacted/timestamp  openaps/enacted/bg  \\\n",
      "9539 2017-04-30 23:54:48+00:00                98.0   \n",
      "9538 2017-05-01 00:18:24+00:00                95.0   \n",
      "9537 2017-05-01 00:25:22+00:00                94.0   \n",
      "9536 2017-05-01 00:25:53+00:00                94.0   \n",
      "9535 2017-05-01 00:28:51+00:00                94.0   \n",
      "...                        ...                 ...   \n",
      "4    2017-07-31 22:55:18+00:00               139.0   \n",
      "3    2017-07-31 23:17:44+00:00               132.0   \n",
      "2    2017-07-31 23:29:40+00:00               125.0   \n",
      "1    2017-07-31 23:39:44+00:00               120.0   \n",
      "0    2017-07-31 23:57:45+00:00               115.0   \n",
      "\n",
      "      openaps/enacted/eventualBG  openaps/enacted/rate  \n",
      "9539                        77.0                  0.15  \n",
      "9538                        90.0                  1.65  \n",
      "9537                        90.0                  2.05  \n",
      "9536                        89.0                  1.55  \n",
      "9535                        90.0                  2.05  \n",
      "...                          ...                   ...  \n",
      "4                          113.0                  2.65  \n",
      "3                           90.0                  1.30  \n",
      "2                           89.0                  1.25  \n",
      "1                           81.0                  0.60  \n",
      "0                           95.0                  1.30  \n",
      "\n",
      "[9540 rows x 4 columns]\n",
      "            openaps/enacted/timestamp  openaps/enacted/bg  \\\n",
      "9524 2019-08-12 15:11:54.405000+00:00               134.0   \n",
      "9523 2019-08-12 15:39:26.204000+00:00               173.0   \n",
      "9522 2019-08-12 15:43:27.046000+00:00               170.0   \n",
      "9521 2019-08-12 15:49:04.417000+00:00               165.0   \n",
      "9520 2019-08-12 15:57:57.571000+00:00               162.0   \n",
      "...                               ...                 ...   \n",
      "4    2019-11-18 05:46:43.184000+00:00               114.0   \n",
      "3    2019-11-18 05:51:28.716000+00:00               118.0   \n",
      "2    2019-11-18 05:56:34.437000+00:00               122.0   \n",
      "1    2019-11-18 06:01:25.569000+00:00               122.0   \n",
      "0    2019-11-18 06:06:46.250000+00:00               115.0   \n",
      "\n",
      "      openaps/enacted/eventualBG  openaps/enacted/rate  \n",
      "9524                       158.0                  2.00  \n",
      "9523                       167.0                  2.00  \n",
      "9522                       185.0                  3.70  \n",
      "9521                       158.0                  1.10  \n",
      "9520                       141.0                  3.70  \n",
      "...                          ...                   ...  \n",
      "4                          117.0                  2.50  \n",
      "3                          150.0                  4.05  \n",
      "2                          126.0                  0.70  \n",
      "1                           82.0                  0.00  \n",
      "0                           86.0                  0.00  \n",
      "\n",
      "[9525 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# In[6]:Creating a dict with participant ID as key and one single concantenated list \n",
    "#of all device status training files with updated time column data type \n",
    "devicestatus_precombined_training_files_convertedto_timedelta = {}\n",
    "for participant in devicestatus_training_files_combined_for_each_participant:    \n",
    "    # All files for each participant need to convert time column openaps/enacted/timestamp requires \n",
    "    #to be converted to different (timedelta) data type in \n",
    "    #training data  which is value in devicestatus_training_files_to_be_merged_for_each_participant\n",
    "    file = devicestatus_training_files_combined_for_each_participant[participant]\n",
    "    #time format in all device status files is not uniform, so far, I have found two formats %Y-%m-%dT%H:%M:%S.%fZ and %Y-%m-%dT%H:%M:%fZ\n",
    "    file['openaps/enacted/timestamp'] = file['openaps/enacted/timestamp'].apply(lambda x: pd.to_datetime(x))\n",
    "    file = file.sort_values(by=['openaps/enacted/timestamp'])   \n",
    "    print(file)\n",
    "#     file['openaps/enacted/timedelta'] = file['openaps/enacted/timestamp'].diff().dt.total_seconds()   \n",
    "#     file['openaps/enacted/timedelta'].iloc[0] = 0\n",
    "#         #print(file['openaps/enacted/timedelta'])\n",
    "#     file.pop('openaps/enacted/timestamp')           \n",
    "    devicestatus_precombined_training_files_convertedto_timedelta[participant] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]: Writing all training data as csv files in local directory \n",
    "for participant in devicestatus_precombined_training_files_convertedto_timedelta:\n",
    "     devicestatus_precombined_training_files_convertedto_timedelta[participant].to_csv('data/DATA_timestamps/' + participant + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
